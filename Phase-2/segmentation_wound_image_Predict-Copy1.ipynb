{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravind/Desktop/tensorflow-env/smart_bandage/wound_segmentation_code/Fully_automatic_wound_segmentation_paper_code/utils/io/data.py:95: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if color_space.lower() is 'hsi' or 'hsv':\n",
      "/Users/aravind/Desktop/tensorflow-env/smart_bandage/wound_segmentation_code/Fully_automatic_wound_segmentation_paper_code/utils/io/data.py:98: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif color_space.lower() is 'lab':\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "from models.unets import Unet2D\n",
    "#from models.separable_unet import Separable_Unet2D\n",
    "from models.deeplab import Deeplabv3, relu6, BilinearUpsampling, DepthwiseConv2D\n",
    "from models.FCN import FCN_Vgg16_16s\n",
    "from models.SegNet import SegNet\n",
    "\n",
    "from utils.learning.metrics import dice_coef, precision, recall\n",
    "from utils.BilinearUpSampling import BilinearUpSampling2D\n",
    "from utils.io.data import load_data, save_results, save_rgb_results, save_history, load_test_images, DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "input_dim_x = 224\n",
    "input_dim_y = 224\n",
    "color_space = 'rgb'\n",
    "path = './data/all_dog_wounds_noAugmentation/'#all_dog_wounds_noAugmentation#Medetec_foot_ulcer_224#Dog_wound_low_resolution#dog9_10_test\n",
    "weight_file_name = 'Unet-dog-w-augment-2021-07-20.hdf5'\n",
    "pred_save_path = 'Unet-dog-w-augment-2021-07-20/'\n",
    "\n",
    "#data_gen = DataGen(path, split_ratio=0.0, x=input_dim_x, y=input_dim_y, color_space=color_space)\n",
    "x_test, test_label_filenames_list = load_test_images(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 15:17:08.625205: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 15:17:08.625928: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# ### get unet model\n",
    "#unet2d = Unet2D(n_filters=64, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "#model = unet2d.get_unet_model_yuanqing()\n",
    "model = load_model('./trained_models/' + weight_file_name,\n",
    "                   custom_objects={'dice_coef': dice_coef,\n",
    "                                  'precision':precision,\n",
    "                                  'recall':recall})\n",
    "\n",
    "# ### get separable unet model\n",
    "# sep_unet = Separable_Unet2D(n_filters=64, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "# model, model_name = sep_unet.get_sep_unet_v2()\n",
    "# model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#                , custom_objects={'dice_coef': dice_coef,\n",
    "#                                  'relu6':relu6,\n",
    "#                                  'DepthwiseConv2D':DepthwiseConv2D,\n",
    "#                                  'BilinearUpsampling':BilinearUpsampling})\n",
    "\n",
    "# ### get VGG16 model\n",
    "# model, model_name = FCN_Vgg16_16s(input_shape=(input_dim_x, input_dim_y, 3))\n",
    "# with CustomObjectScope({'BilinearUpSampling2D':BilinearUpSampling2D}):\n",
    "#     model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#                    , custom_objects={'dice_coef': dice_coef})\n",
    "\n",
    "# ### get mobilenetv2 model\n",
    "#model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
    "#model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#               , custom_objects={'dice_coef': dice_coef,\n",
    "#                                 'relu6':relu6,\n",
    "#                                 'DepthwiseConv2D':DepthwiseConv2D,\n",
    "#                                 'BilinearUpsampling':BilinearUpsampling})\n",
    "\n",
    "# ### get segnet model\n",
    "######### SegNet ##########\n",
    "#segnet = SegNet(n_filters=32, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "#model, model_name = segnet.get_SegNet()\n",
    "#model = load_model('./merged_azh_dog1_8_history/' + weight_file_name,\n",
    "#                   custom_objects={'dice_coef': dice_coef,\n",
    "#                                  'precision':precision,\n",
    "#                                  'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, None,   896         ['input_1[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, None,   9248        ['conv2d[0][0]']                 \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['conv2d_1[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, None, None,   18496       ['max_pooling2d[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, None, None,   36928       ['conv2d_2[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['conv2d_3[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, None, None,   73856       ['max_pooling2d_1[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, None, None,   147584      ['conv2d_4[0][0]']               \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, None, None,   147584      ['conv2d_5[0][0]']               \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['conv2d_6[0][0]']               \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, None, None,   295168      ['max_pooling2d_2[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, None, None,   590080      ['conv2d_7[0][0]']               \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, None, None,   590080      ['conv2d_8[0][0]']               \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['conv2d_9[0][0]']               \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, None, None,   590080      ['max_pooling2d_3[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, None, None,   590080      ['conv2d_10[0][0]']              \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, None, None,   590080      ['conv2d_11[0][0]']              \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, None, None,   0           ['conv2d_12[0][0]']              \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, None, None,   295040      ['conv2d_9[0][0]']               \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, None, None,   131200      ['up_sampling2d[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, None,   0           ['conv2d_14[0][0]',              \n",
      "                                256)                              'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, None, None,   295040      ['concatenate[0][0]']            \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, None, None,   147584      ['conv2d_15[0][0]']              \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, None, None,   0          ['conv2d_16[0][0]']              \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, None, None,   73792       ['conv2d_6[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, None, None,   32832       ['up_sampling2d_1[0][0]']        \n",
      "                                64)                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, None, None,   0           ['conv2d_18[0][0]',              \n",
      "                                128)                              'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, None, None,   73792       ['concatenate_1[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, None, None,   36928       ['conv2d_19[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, None, None,   0          ['conv2d_20[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, None, None,   18464       ['conv2d_3[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, None, None,   8224        ['up_sampling2d_2[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, None,   0           ['conv2d_22[0][0]',              \n",
      "                                64)                               'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, None, None,   18464       ['concatenate_2[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, None, None,   9248        ['conv2d_23[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, None, None,   0          ['conv2d_24[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, None, None,   4624        ['conv2d_1[0][0]']               \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, None, None,   2064        ['up_sampling2d_3[0][0]']        \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, None, None,   0           ['conv2d_26[0][0]',              \n",
      "                                32)                               'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, None, None,   4624        ['concatenate_3[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, None, None,   2320        ['conv2d_27[0][0]']              \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, None, None,   435         ['conv2d_28[0][0]']              \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, None, None,   4           ['conv2d_29[0][0]']              \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,834,839\n",
      "Trainable params: 4,834,839\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 15:17:32.451410: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-28 15:17:32.878603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 397ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predicted mask images\n",
    "prediction = model.predict(x_test, verbose=1)\n",
    "save_results(prediction, 'rgb', path + 'predictions/' + pred_save_path, test_label_filenames_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the wound area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame to store wound area results\n",
    "wound_area_df = pd.DataFrame(columns = ['Pixel_Area'], index = test_label_filenames_list) \n",
    "\n",
    "for i in range(len(test_label_filenames_list)):\n",
    "    pred = prediction[i]\n",
    "    ret, pred_bw = cv2.threshold(pred*255., 127, 255, cv2.THRESH_BINARY) \n",
    "    wound_area_df.iloc[i,0] = cv2.countNonZero(pred_bw)\n",
    "#print(wound_area_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract date and dog label information from row name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['-01-CON-D00-L.png', '-01-CON-D02-L.png', '-01-CON-D04-L.png',\n",
      "       '-01-CON-D07-L.png', '-01-CON-D09-L.png', '-01-CON-D11-L.png',\n",
      "       '-01-CON-D14-L.png', '-01-CON-D16-L.png', '-01-CON-D18-L.png',\n",
      "       '-01-CON-D21-L.png',\n",
      "       ...\n",
      "       'rotate90-10-CON-D04-R.png', 'rotate90-10-CON-D07-R.png',\n",
      "       'rotate90-10-CON-D09-R.png', 'rotate90-10-CON-D11-R.png',\n",
      "       'rotate90-10-CON-D14-R.png', 'rotate90-10-CON-D16-R.png',\n",
      "       'rotate90-10-CON-D18-R.png', 'rotate90-10-CON-D21-R.png',\n",
      "       'rotate90-10-CON-D23-R.png', 'rotate90-10-CON-D25-R.png'],\n",
      "      dtype='object', length=544)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for i in range(len(wound_area_df.index)):\n",
    "    wound_area_df.loc[wound_area_df.index[i], 'Day'] = int(wound_area_df.index[i].split('-D')[1].split('-')[0])\n",
    "    wound_area_df.loc[wound_area_df.index[i], 'Dog_label'] = wound_area_df.index[i].split('-')[1].split('-CON')[0]\n",
    "print(wound_area_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the ratio by calculate the pixel length of 1cm ruler on image\n",
    "\n",
    "Currently just manually count pixel length of 1 cm ruler\n",
    "Alternatives: \n",
    "1. Hough transform for line detection\n",
    "2. A separate NN for ruler detection, and count the 1 cm ruler area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dog 9 and 10 ration manually picked\n",
    "#wound_area_df.loc[:,'Ratio'] = [56, 59, 52, 50, 60, 61, 59, 63, 61, 64, 71, 73, 74, 114,\n",
    "#                             50, 54, 54, 57, 57, 59, 50, 68, 81, 70, 68, 59]\n",
    "\n",
    "# All dog wound images' ratio, could also read in from file wound_image_labels.csv\n",
    "wound_area_df.loc[:,'Ratio'] = [35,66,53,54,77,70,62,72,71,71,89,81,65,68,69,30,48,60,66,65,\n",
    "66,66,64,74,57,69,75,73,74,82,35,56,51,62,69,74,79,90,73,66,73,72,69,74,52,33,40,52,58,66,69,\n",
    "48,69,68,55,62,64,79,83,64,50,58,64,75,75,96,70,75,63,72,51,48,53,45,53,53,54,50,55,54,67,72,\n",
    "78,69,60,51,50,57,53,60,53,55,70,71,80,91,86,70,55,57,52,65,60,69,62,75,80,76,80,82,56,59,52,\n",
    "50,60,61,59,63,61,64,71,73,74,114,50,54,54,57,57,59,50,68,81,70,68,59]*4\n",
    "\n",
    "wound_area_df.loc[:,'Area_mm2'] = wound_area_df.loc[:,'Pixel_Area']*100 / (wound_area_df.loc[:,'Ratio']**2)\n",
    "#print(wound_area_df)\n",
    "wound_area_df = wound_area_df[['Day', 'Dog_label', 'Area_mm2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Day Dog_label    Area_mm2\n",
      "-07-CON-D00-R.png            0.0        07       451.2\n",
      "-07-CON-D02-R.png            2.0        07  526.008002\n",
      "-07-CON-D04-R.png            4.0        07  428.764685\n",
      "-07-CON-D07-R.png            7.0        07  450.777778\n",
      "-07-CON-D09-R.png            9.0        07  244.357423\n",
      "-07-CON-D11-R.png           11.0        07  146.115702\n",
      "-07-CON-D14-R.png           14.0        07   81.469388\n",
      "-07-CON-D16-R.png           16.0        07   64.411823\n",
      "-07-CON-D18-R.png           18.0        07     38.3125\n",
      "-07-CON-D21-R.png           21.0        07   28.728414\n",
      "-07-CON-D23-R.png           23.0        07   17.225527\n",
      "-07-CON-D25-R.png           25.0        07    5.918367\n",
      "rotate180-07-CON-D00-R.png   0.0        07      449.44\n",
      "rotate180-07-CON-D02-R.png   2.0        07  537.765466\n",
      "rotate180-07-CON-D04-R.png   4.0        07  426.521894\n",
      "rotate180-07-CON-D07-R.png   7.0        07  449.055556\n",
      "rotate180-07-CON-D09-R.png   9.0        07  243.004628\n",
      "rotate180-07-CON-D11-R.png  11.0        07  136.958678\n",
      "rotate180-07-CON-D14-R.png  14.0        07    82.77551\n",
      "rotate180-07-CON-D16-R.png  16.0        07   65.443364\n",
      "rotate180-07-CON-D18-R.png  18.0        07     32.9375\n",
      "rotate180-07-CON-D21-R.png  21.0        07   29.827316\n",
      "rotate180-07-CON-D23-R.png  23.0        07   11.695511\n",
      "rotate180-07-CON-D25-R.png  25.0        07    8.918367\n",
      "rotate270-07-CON-D00-R.png   0.0        07      438.48\n",
      "rotate270-07-CON-D02-R.png   2.0        07  533.240997\n",
      "rotate270-07-CON-D04-R.png   4.0        07  421.288715\n",
      "rotate270-07-CON-D07-R.png   7.0        07  448.916667\n",
      "rotate270-07-CON-D09-R.png   9.0        07  251.406194\n",
      "rotate270-07-CON-D11-R.png  11.0        07  144.165289\n",
      "rotate270-07-CON-D14-R.png  14.0        07   88.857143\n",
      "rotate270-07-CON-D16-R.png  16.0        07   64.173775\n",
      "rotate270-07-CON-D18-R.png  18.0        07   32.390625\n",
      "rotate270-07-CON-D21-R.png  21.0        07   26.675522\n",
      "rotate270-07-CON-D23-R.png  23.0        07   14.670092\n",
      "rotate270-07-CON-D25-R.png  25.0        07    8.306122\n",
      "rotate90-07-CON-D00-R.png    0.0        07      449.72\n",
      "rotate90-07-CON-D02-R.png    2.0        07  534.472145\n",
      "rotate90-07-CON-D04-R.png    4.0        07  426.949092\n",
      "rotate90-07-CON-D07-R.png    7.0        07  446.722222\n",
      "rotate90-07-CON-D09-R.png    9.0        07  246.137415\n",
      "rotate90-07-CON-D11-R.png   11.0        07   138.14876\n",
      "rotate90-07-CON-D14-R.png   14.0        07   89.877551\n",
      "rotate90-07-CON-D16-R.png   16.0        07    66.81214\n",
      "rotate90-07-CON-D18-R.png   18.0        07   35.796875\n",
      "rotate90-07-CON-D21-R.png   21.0        07    26.56684\n",
      "rotate90-07-CON-D23-R.png   23.0        07    9.775554\n",
      "rotate90-07-CON-D25-R.png   25.0        07    7.306122\n"
     ]
    }
   ],
   "source": [
    "print(wound_area_df[wound_area_df.Dog_label == \"07\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the intermediate layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/17 [>.............................] - ETA: 3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 15:18:03.457467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 3s 182ms/step\n",
      "(544, 14, 14, 256)\n",
      "(544, 50176)\n",
      "Are there any NA value? :  False\n"
     ]
    }
   ],
   "source": [
    "# Extract the intermediate layer as features\n",
    "########### SegNet ####################################\n",
    "# !check the summary to confirm which layer to extract\n",
    "#\n",
    "# Segnet: use 'conv2d_5'\n",
    "# Unet: use 'conv2d_12'\n",
    "\n",
    "layer_name = 'conv2d_12'\n",
    "#layer_name = 'conv2d_5'\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_test)\n",
    "print(intermediate_output.shape)\n",
    "# flatten the extracted features using the 1-3 column\n",
    "intermediate_output_flatten = intermediate_output.reshape((intermediate_output.shape[0],\n",
    "                                                           intermediate_output.shape[1] * \n",
    "                                                           intermediate_output.shape[2] * \n",
    "                                                           intermediate_output.shape[3]))\n",
    "print(intermediate_output_flatten.shape)\n",
    "print(\"Are there any NA value? : \", np.any(np.isnan(intermediate_output_flatten)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3        4      5      6      7      8      9      \\\n",
       "0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0  0.95464    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...     50166  50167  50168  50169  50170  50171  50172  50173  50174  \\\n",
       "0  ...  0.141904    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  ...  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  ...  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      50175  \n",
       "0  0.000000  \n",
       "1  0.005005  \n",
       "2  0.000000  \n",
       "\n",
       "[3 rows x 50176 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use PCA to reduce dimension to 50 for the regression model\n",
    "\n",
    "# change to a pandas dataframe\n",
    "og_data = pd.DataFrame(intermediate_output_flatten, index = test_label_filenames_list)\n",
    "#og_data.shape\n",
    "#print(og_data)\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "#minmax data transformation\n",
    "from sklearn import preprocessing\n",
    "#built up data frame\n",
    "from pandas import DataFrame, Series\n",
    "norm_data = og_data\n",
    "\n",
    "# Scale RNAseq data using zero-one normalization\n",
    "norm_data_zerone = preprocessing.MinMaxScaler().fit_transform(norm_data)\n",
    "\n",
    "# If select the minmax method\n",
    "norm_data = pd.DataFrame(norm_data_zerone)\n",
    "norm_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Projection using Minka's MLE\n",
    "from sklearn.decomposition import PCA\n",
    "# use this, if selecting the amount of variance that needs to be explained is greater than the percentage specified by n_components.\n",
    "# or assign a certain components number, e.g. 50\n",
    "pca = PCA(n_components = 0.95, svd_solver = 'full')\n",
    "#pca = PCA(n_components = 50, svd_solver = 'auto')\n",
    "#print(pca)\n",
    "principalComponents = pca.fit_transform(norm_data)\n",
    "principalDf = pd.DataFrame(data = principalComponents, index = test_label_filenames_list)\n",
    "#principalDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Dataset Explained Variance')\n",
    "#plt.savefig('PCA_Explained_Variance(thre_0.9).png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE compression\n",
    "## Split 10% of the data as test set randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of training dataset is:  (490, 50176)\n"
     ]
    }
   ],
   "source": [
    "#import the data as training data\n",
    "#set the random state to 42\n",
    "\n",
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "Exprframe_test = norm_data.sample(frac=test_set_percent, random_state = 42)\n",
    "Exprframe_train = norm_data.drop(Exprframe_test.index)\n",
    "print(\"The dimension of training dataset is: \",Exprframe_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions and classes\n",
    "* This will facilitate connections between layers and also custom hyperparameters\n",
    "\n",
    "## Implementing Warm-up as described in Sonderby et al. LVAE\n",
    "\n",
    "* This is modified code from https://github.com/fchollet/keras/issues/2595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras import losses\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "from keras import utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "    This function is borrowed from:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    #def vae_loss(self, x_input, x_decoded):\n",
    "    #    reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "    #    kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "    #                            K.exp(z_log_var_encoded), axis=-1)\n",
    "    #    return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "    \n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        #per sample\n",
    "        reconstruction_loss = original_dim * losses.mean_absolute_error(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        \n",
    "        #\n",
    "        #per data point\n",
    "        #reconstruction_loss = losses.mean_absolute_error(x_input, x_decoded)\n",
    "        #kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "        #                        K.exp(z_log_var_encoded), axis=-1) / latent_dim\n",
    "        \n",
    "        \n",
    "        return K.mean(reconstruction_loss + alpha * (kl_loss))#K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x\n",
    "    \n",
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/qg/n_qkcysd0vxfsffsxdxmyqq80000gn/T/ipykernel_25007/2406779342.py:2: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n",
      "The dimension of input layer is:  50176\n",
      "The batch size is:  4\n"
     ]
    }
   ],
   "source": [
    "# Set hyper parameters\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "original_dim = Exprframe_train.shape[1]\n",
    "print(\"The dimension of input layer is: \", original_dim)\n",
    "\n",
    "layer1_dim, layer2_dim, layer3_dim, layer4_dim, layer5_dim, latent_dim = 6000, 3000, 1000,500,100,50\n",
    "\n",
    "batch_size = 4 #Exprframe_train.shape[0]\n",
    "print(\"The batch size is: \", batch_size)\n",
    "epochs, learning_rate = 1200, 0.002\n",
    "\n",
    "#set kernel initializer\n",
    "# Casey paper 'glorot_uniform'\n",
    "#initial_method = 'glorot_uniform'\n",
    "#initial_method = keras.initializers.glorot_uniform(seed=807)\n",
    "initial_method = keras.initializers.glorot_normal(seed=42)\n",
    "\n",
    "epsilon_std, alpha, beta, kappa = 1.0, 1.0, K.variable(0), 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple neural network version with two layers\n",
    "#Layer 1\n",
    "# Input place holder for RNAseq data with specific input size\n",
    "rnaseq_input = Input(shape=(original_dim, ))\n",
    "\n",
    "#L1\n",
    "l1_dense_linear = Dense(layer1_dim, kernel_initializer=initial_method)(rnaseq_input)\n",
    "l1_dense_batchnorm = BatchNormalization()(l1_dense_linear)\n",
    "l1 = Activation('relu')(l1_dense_batchnorm)\n",
    "\n",
    "#l2\n",
    "l2_dense_linear = Dense(layer2_dim, kernel_initializer=initial_method)(l1)\n",
    "l2_dense_batchnorm = BatchNormalization()(l2_dense_linear)\n",
    "l2 = Activation('relu')(l2_dense_batchnorm)\n",
    "\n",
    "#l3\n",
    "l3_dense_linear = Dense(layer3_dim, kernel_initializer=initial_method)(l2)\n",
    "l3_dense_batchnorm = BatchNormalization()(l3_dense_linear)\n",
    "l3 = Activation('relu')(l3_dense_batchnorm)\n",
    "\n",
    "#l4\n",
    "l4_dense_linear = Dense(layer4_dim, kernel_initializer=initial_method)(l3)\n",
    "l4_dense_batchnorm = BatchNormalization()(l4_dense_linear)\n",
    "l4 = Activation('relu')(l4_dense_batchnorm)\n",
    "\n",
    "#l5\n",
    "l5_dense_linear = Dense(layer5_dim, kernel_initializer=initial_method)(l4)\n",
    "l5_dense_batchnorm = BatchNormalization()(l5_dense_linear)\n",
    "l5 = Activation('relu')(l5_dense_batchnorm)\n",
    "\n",
    "#Layer 6\n",
    "# Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "# Each layer is initialized with glorot uniform weights and each step (dense connections,\n",
    "# batch norm, and relu activation) are funneled separately\n",
    "# Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l5)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l5)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# return the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoding layers have 6 layers and relu activation\n",
    "decoderl5_reconstruct = Dense(layer5_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l5 = decoderl5_reconstruct(z)\n",
    "\n",
    "decoderl4_reconstruct = Dense(layer4_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l4 = decoderl4_reconstruct(decoder_l5)\n",
    "\n",
    "decoderl3_reconstruct = Dense(layer3_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l3 = decoderl3_reconstruct(decoder_l4)\n",
    "\n",
    "decoderl2_reconstruct = Dense(layer2_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l2 = decoderl2_reconstruct(decoder_l3)\n",
    "\n",
    "decoderl1_reconstruct = Dense(layer1_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l1 = decoderl1_reconstruct(decoder_l2)\n",
    "\n",
    "decoderl0_reconstruct = Dense(original_dim, kernel_initializer=initial_method, activation='relu')\n",
    "rnaseq_reconstruct = decoderl0_reconstruct(decoder_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the encoder and decoder to make the VAE\n",
    "\n",
    "* The CustomVariationalLayer() includes the VAE loss function (reconstruction + (beta * KL)), which is what will drive our model to learn an interpretable representation of gene expression space.\n",
    "\n",
    "* The VAE is compiled with an Adam optimizer and built-in custom loss function. The loss_weights parameter ensures beta is updated at each epoch end callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravind/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50176)]      0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6000)         301062000   ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 6000)        24000       ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 6000)         0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3000)         18003000    ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 3000)        12000       ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 3000)         0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1000)         3001000     ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1000)        4000        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1000)         0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 500)          500500      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 500)         2000        ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 500)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          50100       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100)         400         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           5050        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           5050        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 50)          200         ['dense_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 50)          200         ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 50)           0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 50)           0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 50)           0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 100)          5100        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 500)          50500       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1000)         501000      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 3000)         3003000     ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 6000)         18006000    ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 50176)        301106176   ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " custom_variational_layer (Cust  (None, 50176)       0           ['input_1[0][0]',                \n",
      " omVariationalLayer)                                              'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 645,341,276\n",
      "Trainable params: 645,319,876\n",
      "Non-trainable params: 21,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "vae_layer = CustomVariationalLayer()([rnaseq_input, rnaseq_reconstruct])\n",
    "vae = Model(rnaseq_input, vae_layer)\n",
    "vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n",
    "\n",
    "#########################################################################\n",
    "#only use to manually set initial weights, otherwise change the initializer\n",
    "weights = vae.get_weights()\n",
    "#new_weight = [item*0+0.01 for item in weights]\n",
    "#vae.set_weights(new_weight)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "* The training data is shuffled after every epoch and 10% of the data is heldout for calculating validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravind/Desktop/tensorflow-env/env/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.math.reduce_sum_2/Sum:0', description=\"created by layer 'tf.math.reduce_sum_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/engine/keras_tensor.py:254\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 254\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    255\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are passing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an intermediate Keras symbolic input/output, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    256\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto a TF API that does not allow registering custom dispatchers, such \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    258\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras Functional model construction only supports \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    259\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF API calls that *do* support dispatching, such as `tf.math.add` or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    260\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tf.reshape`. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    261\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    262\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs/outputs. You can work around \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    263\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    264\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`call` and calling that layer \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    265\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon this symbolic input/output.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.math.reduce_sum_2/Sum:0', description=\"created by layer 'tf.math.reduce_sum_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = vae.fit(np.array(Exprframe_train),\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               verbose=0,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(np.array(Exprframe_test), None),\n",
    "               callbacks=[WarmUpCallback(beta, kappa)])#,\n",
    "                          #TQDMNotebookCallback(leave_inner=True, leave_outer=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize VAE training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "history_df = history_df.iloc[60:1199]\n",
    "\n",
    "hist_plot_file = \"temp.pdf\"#\n",
    "ax = history_df.plot()\n",
    "\n",
    "ratio = 0.95\n",
    "xleft, xright = ax.get_xlim()\n",
    "ybottom, ytop = ax.get_ylim()\n",
    "# the abs method is used to make sure that all numbers are positive\n",
    "# because x and y axis of an axes maybe inversed.\n",
    "ax.set_aspect(abs((xright-xleft)/(ybottom-ytop))*ratio)\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('objective function (include both reconstruct_loss, kl_loss)')\n",
    "ax.set_title('')\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the encoder part\n",
    "encoder = Model(rnaseq_input, z)\n",
    "#encoder.summary()\n",
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "z_df = encoder.predict_on_batch(Exprframe_test)\n",
    "\n",
    "z_df = pd.DataFrame(z_df, index=Exprframe_test.index)\n",
    "\n",
    "z_df.columns.name = 'sample_id'\n",
    "z_df.columns = z_df.columns + 1\n",
    "z_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim, ))  # can generate from any sampled z vector\n",
    "\n",
    "_x_decoded_l5 = decoderl5_reconstruct(decoder_input)\n",
    "_x_decoded_l4 = decoderl4_reconstruct(_x_decoded_l5)\n",
    "_x_decoded_l3 = decoderl3_reconstruct(_x_decoded_l4)\n",
    "\n",
    "_x_decoded_l2 = decoderl2_reconstruct(_x_decoded_l3)\n",
    "\n",
    "_x_decoded_l1 = decoderl1_reconstruct(_x_decoded_l2)\n",
    "_x_decoded_l0 = decoderl0_reconstruct(_x_decoded_l1)\n",
    "\n",
    "decoder = Model(decoder_input, _x_decoded_l0)\n",
    "#decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe reconstruction fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original input RNAseq data\n",
    "Exprframe_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does the model reconstruct the input RNAseq data\n",
    "input_rnaseq_reconstruct = decoder.predict(np.array(z_df))\n",
    "input_rnaseq_reconstruct = pd.DataFrame(input_rnaseq_reconstruct, index=Exprframe_test.index,\n",
    "                                        columns=Exprframe_test.columns)\n",
    "input_rnaseq_reconstruct.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the mean reconstruction loss and the mean KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# L1 loss: losses.mean_absolute_error\n",
    "reconstruction_loss_used = losses.mean_absolute_error(Exprframe_test, input_rnaseq_reconstruct) #* original_dim\n",
    "with tf.Session() as sess:\n",
    "    #print the reconstruction loss that we calculated\n",
    "    mean_reconstruct_loss = sess.run(K.mean(reconstruction_loss_used))\n",
    "    print (\"The mean reconstruction loss for each data point is: %.11f\" % mean_reconstruct_loss)\n",
    "\n",
    "#kl_loss = - 0.5 * K.sum(1 + z_log_var_d - K.square(z_mean_d) - \n",
    "#                                K.exp(z_log_var_d), axis=-1) / latent_dim\n",
    "#with tf.Session() as sess:\n",
    "    #print the kl loss that we calculated\n",
    "#    mean_kl_loss = sess.run(K.mean(kl_loss))\n",
    "#    print (\"The mean KL loss for each data point is: %.11f\" %mean_kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with area/day information and Save the compressed encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For uncompressed data\n",
    "#out_df = og_data.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# For PCA compressed:\n",
    "out_df = principalDf.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# For VAE compressed:\n",
    "#z_df = encoder.predict_on_batch(Exprframe)\n",
    "#z_df = pd.DataFrame(z_df, index=Exprframe.index)\n",
    "#z_df.columns.name = 'sample_id'\n",
    "#z_df.columns = z_df.columns + 1\n",
    "#out_df = z_df.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "#out_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_file_path = path + 'extracted_features/' + pred_save_path\n",
    "# uncompressed: uncompressed_features_rotations.csv\n",
    "# pca compressed: pca_compressed_features_rotations.csv\n",
    "# vae compressed: VAE-1_compressed_features_rotations.csv\n",
    "out_df.to_csv(encoded_file_path + 'pca_compressed_features_rotations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(path + 'predictions/' + pred_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_batch, label_batch in data_gen.generate_data(batch_size=len(x_test), test=True):\n",
    "#    prediction = model.predict(image_batch, verbose=1)\n",
    "    #save_results(prediction, 'rgb', path + 'test/predictions/' + pred_save_path, test_label_filenames_list)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
