{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and use tensorflow as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install requests\n",
    "#import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras import losses\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "from keras import utils\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#from .tqdm_callback import TQDMNotebookCallback\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "10 + 32 =  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:30:02.284300: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:30:02.284514: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-28 12:30:02.289124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-07-28 12:30:02.296112: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-28 12:30:02.330170: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#test tensorflow, remember to change the kernel\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(\"10 + 32 = \", sess.run(a + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whether tensorflow is built with cuda:  False\n",
      "WARNING:tensorflow:From /var/folders/qg/n_qkcysd0vxfsffsxdxmyqq80000gn/T/ipykernel_23471/1185953119.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "whether gpu computing is available for tensorflow:  True\n",
      "using keras version:  2.9.0\n",
      "using tensorflow version:  2.9.2\n",
      "\n",
      "\n",
      "Device details:\n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3704716250118109591\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 2164625456846212488\n",
      "physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:30:17.552506: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:30:17.552653: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-28 12:30:17.554870: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:30:17.554937: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-28 12:30:17.556698: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:30:17.556737: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-28 12:30:17.557095: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:30:17.557118: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "#check the system information, check if cuda and gpu computing for tensorflow is installed properly\n",
    "######################################################################################################\n",
    "print(\"whether tensorflow is built with cuda: \", tf.test.is_built_with_cuda())\n",
    "print(\"whether gpu computing is available for tensorflow: \", tf.test.is_gpu_available())\n",
    "print(\"using keras version: \", keras.__version__)\n",
    "print(\"using tensorflow version: \", tf.__version__)\n",
    "print(\"\\n\")\n",
    "print(\"Device details:\\n\", device_lib.list_local_devices())\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files/documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input dataset is:  (544, 50176)\n"
     ]
    }
   ],
   "source": [
    "#Reading files/documents\n",
    "#using all unlabeled data\n",
    "path = './data/all_dog_wounds_noAugmentation/extracted_features/'\n",
    "pred_save_path = '2021-05-05 02:22:24.668040/'\n",
    "feature_path = path + pred_save_path + \"nocompression_features_rotations.csv\"\n",
    "#only use labeled data\n",
    "#path = \"counts_data/counts_data_without_label/TCGA_SARC_(0.2chemo_45samples)VSTnrom_count_expr_clinical_data.tsv\"\n",
    "\n",
    "#open(path).readline()\n",
    "#gene expression RNAseq, Batch effects normalized mRNA data\n",
    "\n",
    "ExprAlldata = pd.read_csv(feature_path, sep = \"\\t\", index_col = 0)\n",
    "ExprAlldata = ExprAlldata.dropna(axis='columns')\n",
    "#ExprAlldata.columns = [\"Gene\", \"Counts\"]\n",
    "print(\"The dimension of input dataset is: \", ExprAlldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-01-CON-D00-L.png</th>\n",
       "      <td>20459.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391696.03</td>\n",
       "      <td>205863.03</td>\n",
       "      <td>516136.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>238339.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>134881.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59028.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-01-CON-D02-L.png</th>\n",
       "      <td>393714.530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22553904.00</td>\n",
       "      <td>6472752.00</td>\n",
       "      <td>24896052.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3545184.00</td>\n",
       "      <td>4688192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>650361.44</td>\n",
       "      <td>1442400.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340351.80</td>\n",
       "      <td>244538.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-01-CON-D04-L.png</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3908632.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5609247.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373565.97</td>\n",
       "      <td>97864.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67994.0</td>\n",
       "      <td>755745.44</td>\n",
       "      <td>417971.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273408.03</td>\n",
       "      <td>299599.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0    1    2    3            4           5  \\\n",
       "-01-CON-D00-L.png   20459.152  0.0  0.0  0.0    391696.03   205863.03   \n",
       "-01-CON-D02-L.png  393714.530  0.0  0.0  0.0  22553904.00  6472752.00   \n",
       "-01-CON-D04-L.png       0.000  0.0  0.0  0.0   3908632.00        0.00   \n",
       "\n",
       "                             6    7           8          9  ...  50166  50167  \\\n",
       "-01-CON-D00-L.png    516136.44  0.0        0.00   238339.1  ...    0.0    0.0   \n",
       "-01-CON-D02-L.png  24896052.00  0.0  3545184.00  4688192.0  ...    0.0    0.0   \n",
       "-01-CON-D04-L.png   5609247.00  0.0   373565.97    97864.1  ...    0.0    0.0   \n",
       "\n",
       "                   50168    50169      50170       50171  50172  50173  \\\n",
       "-01-CON-D00-L.png    0.0      0.0       0.00   134881.44    0.0    0.0   \n",
       "-01-CON-D02-L.png    0.0      0.0  650361.44  1442400.40    0.0    0.0   \n",
       "-01-CON-D04-L.png    0.0  67994.0  755745.44   417971.34    0.0    0.0   \n",
       "\n",
       "                       50174       50175  \n",
       "-01-CON-D00-L.png       0.00   59028.918  \n",
       "-01-CON-D02-L.png  340351.80  244538.940  \n",
       "-01-CON-D04-L.png  273408.03  299599.470  \n",
       "\n",
       "[3 rows x 50176 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExprAlldata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There exists NA value: False\n",
      "All values are finite: True\n"
     ]
    }
   ],
   "source": [
    "any_na = np.any(np.isnan(ExprAlldata))\n",
    "print ('There exists NA value: ' + repr (any_na))\n",
    "\n",
    "all_finite = np.all(np.isfinite(ExprAlldata))\n",
    "print ('All values are finite: ' + repr (all_finite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data normalization choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544, 50176)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minmax data transformation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#built up data frame\n",
    "from pandas import DataFrame, Series\n",
    "Exprframe = DataFrame(ExprAlldata)\n",
    "#Exprframe = ExprAlldata.T\n",
    "Exprframe_og = Exprframe\n",
    "\n",
    "# Scale RNAseq data using zero-one normalization\n",
    "Exprframe_zerone = preprocessing.MinMaxScaler().fit_transform(Exprframe)\n",
    "Exprframe_zerone.shape\n",
    "\n",
    "#change column name\n",
    "#Exprframe.columns.values[0] = \"Gene\"\n",
    "\n",
    "#set rownames\n",
    "#Exprframe = Exprframe.set_index('Gene')\n",
    "#Exprframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic transformation, logistic sigmoid function\n",
    "#def logits(x):\n",
    "#    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#Exprframe_logit = logits(Exprframe)\n",
    "#Exprframe_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#scaler.fit((Exprframe))\n",
    "#Exprfram_std = scaler.transform(Exprframe)\n",
    "#Exprfram_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If select the minmax method\n",
    "Exprframe = pd.DataFrame(Exprframe_zerone,\n",
    "                         columns=Exprframe.columns,\n",
    "                         index=Exprframe.index)\n",
    "\n",
    "# If select the logistic transformation method\n",
    "#Exprframe = pd.DataFrame(Exprframe_logit,\n",
    "#                         columns=Exprframe.columns,\n",
    "#                         index=Exprframe.index)\n",
    "\n",
    "# If select the Standardization method\n",
    "#Exprframe = pd.DataFrame(Exprfram_std,\n",
    "#                         columns=Exprframe.columns,\n",
    "#                         index=Exprframe.index)\n",
    "\n",
    "# If use no transformation\n",
    "#Exprframe = Exprframe_og\n",
    "\n",
    "#print(Exprframe.shape)\n",
    "#Exprframe.head(3)\n",
    "\n",
    "#output log transformed data\n",
    "#log_file = \"counts_data/vae_compressed/log_transformed(0.2_var,3layers,0.1test,log).tsv\"\n",
    "#Exprframe.to_csv(log_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of genes is 50176\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#contruct training dataset\n",
    "n_genes = Exprframe.shape[1]\n",
    "print ('number of genes is ' + repr (n_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split 10% of the data as test set randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of training dataset is:  (490, 50176)\n"
     ]
    }
   ],
   "source": [
    "#import the data as training data\n",
    "#set the random state to 42\n",
    "\n",
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "Exprframe_test = Exprframe.sample(frac=test_set_percent, random_state = 42)\n",
    "Exprframe_train = Exprframe.drop(Exprframe_test.index)\n",
    "print(\"The dimension of training dataset is: \",Exprframe_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load functions and classes\n",
    "* This will facilitate connections between layers and also custom hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "    This function is borrowed from:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    #def vae_loss(self, x_input, x_decoded):\n",
    "    #    reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "    #    kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "    #                            K.exp(z_log_var_encoded), axis=-1)\n",
    "    #    return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "    \n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        #per sample\n",
    "        reconstruction_loss = original_dim * losses.mean_absolute_error(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        \n",
    "        #\n",
    "        #per data point\n",
    "        #reconstruction_loss = losses.mean_absolute_error(x_input, x_decoded)\n",
    "        #kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "        #                        K.exp(z_log_var_encoded), axis=-1) / latent_dim\n",
    "        \n",
    "        \n",
    "        return K.mean(reconstruction_loss + alpha * (kl_loss))#K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Warm-up as described in Sonderby et al. LVAE\n",
    "\n",
    "* This is modified code from https://github.com/fchollet/keras/issues/2595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input layer is:  50176\n"
     ]
    }
   ],
   "source": [
    "# Set hyper parameters\n",
    "original_dim = Exprframe.shape[1]\n",
    "print(\"The dimension of input layer is: \", original_dim)\n",
    "\n",
    "layer1_dim = 2000\n",
    "latent_dim = 500\n",
    "\n",
    "batch_size = 20 #Exprframe.shape[0]\n",
    "epochs = 700\n",
    "learning_rate = 0.002\n",
    "\n",
    "#set kernel initializer\n",
    "# Casey paper 'glorot_uniform'\n",
    "#initial_method = 'glorot_uniform'\n",
    "#initial_method = keras.initializers.glorot_uniform(seed=807)\n",
    "\n",
    "initial_method = keras.initializers.glorot_normal(seed=42)\n",
    "\n",
    "epsilon_std = 1.0\n",
    "alpha = 1.0\n",
    "\n",
    "beta = K.variable(0)\n",
    "kappa = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aravind/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#simple neural network version with two layers\n",
    "#Layer 1\n",
    "# Input place holder for RNAseq data with specific input size\n",
    "rnaseq_input = Input(shape=(original_dim, ))\n",
    "\n",
    "#L1\n",
    "l1_dense_linear = Dense(layer1_dim, kernel_initializer=initial_method)(rnaseq_input)\n",
    "l1_dense_batchnorm = BatchNormalization()(l1_dense_linear)\n",
    "l1 = Activation('relu')(l1_dense_batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 6\n",
    "# Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "# Each layer is initialized with glorot uniform weights and each step (dense connections,\n",
    "# batch norm, and relu activation) are funneled separately\n",
    "# Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l1)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l1)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# return the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoding layers have 2 layers and relu activation\n",
    "decoderl1_reconstruct = Dense(layer1_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l1 = decoderl1_reconstruct(z)\n",
    "\n",
    "decoderl0_reconstruct = Dense(original_dim, kernel_initializer=initial_method, activation='relu')\n",
    "rnaseq_reconstruct = decoderl0_reconstruct(decoder_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the encoder and decoder to make the VAE\n",
    "\n",
    "* The CustomVariationalLayer() includes the VAE loss function (reconstruction + (beta * KL)), which is what will drive our model to learn an interpretable representation of gene expression space.\n",
    "\n",
    "* The VAE is compiled with an Adam optimizer and built-in custom loss function. The loss_weights parameter ensures beta is updated at each epoch end callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output custom_variational_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravind/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2022-07-28 12:33:32.912068: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-28 12:33:32.912111: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-28 12:33:32.922888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-28 12:33:32.941510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-28 12:33:34.570858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50176)]      0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2000)         100354000   ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2000)        8000        ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2000)         0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 500)          1000500     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 500)          1000500     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500)         2000        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500)         2000        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 500)          0           ['activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2000)         1002000     ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 50176)        100402176   ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " custom_variational_layer (Cust  (None, 50176)       0           ['input_1[0][0]',                \n",
      " omVariationalLayer)                                              'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 203,771,176\n",
      "Trainable params: 203,765,176\n",
      "Non-trainable params: 6,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "vae_layer = CustomVariationalLayer()([rnaseq_input, rnaseq_reconstruct])\n",
    "vae = Model(rnaseq_input, vae_layer)\n",
    "vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n",
    "#vae.compile(optimizer=adam, loss=losses.kullback_leibler_divergence)\n",
    "\n",
    "#########################################################################\n",
    "#only use to manually set initial weights, otherwise change the initializer\n",
    "weights = vae.get_weights()\n",
    "#new_weight = [item*0+0.01 for item in weights]\n",
    "#vae.set_weights(new_weight)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "* The training data is shuffled after every epoch and 10% of the data is heldout for calculating validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433fa48556814da689f9e52ccc0c4f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03845e6dad574b0ba3e8ad1933f4247b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/engine/training_v1.py:776\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    775\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/engine/training_arrays_v1.py:641\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    638\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    639\u001b[0m   val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/engine/training_arrays_v1.py:388\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Callbacks batch end.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m batch_logs \u001b[38;5;241m=\u001b[39m cbks\u001b[38;5;241m.\u001b[39mmake_logs(model, batch_logs, batch_outs, mode)\n\u001b[0;32m--> 388\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras/callbacks.py:724\u001b[0m, in \u001b[0;36mCallback.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m\"\"\"Called at the end of a training batch in `fit` methods.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03mSubclasses should override for any actions to run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;66;03m# For backwards compatibility.\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras_tqdm/tqdm_callback.py:117\u001b[0m, in \u001b[0;36mTQDMCallback.on_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m update\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_total:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_metrics(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_logs)\n\u001b[1;32m    119\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_description_update\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/Desktop/tensorflow-env/env/lib/python3.10/site-packages/keras_tqdm/tqdm_callback.py:142\u001b[0m, in \u001b[0;36mTQDMCallback.append_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_logs[metric]\u001b[38;5;241m.\u001b[39mappend(value[()])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_logs[metric] \u001b[38;5;241m=\u001b[39m [\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = vae.fit(np.array(Exprframe_train),\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               verbose=0,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(np.array(Exprframe_test), None),\n",
    "               callbacks=[WarmUpCallback(beta, kappa),\n",
    "                          TQDMNotebookCallback(leave_inner=True, leave_outer=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss        1629.669204\n",
       "val_loss    1551.681360\n",
       "Name: 699, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hist.history\n",
    "z5000_df = pd.DataFrame(hist.history)\n",
    "z5000_df.loc[699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca8c556a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "history_df = history_df.iloc[60:699]\n",
    "\n",
    "hist_plot_file = \"temp.pdf\"#\"(Lr_0.002)(NN6K_z100_a1.0_6L_0.1t)obj_func_per_dp(4cancers).pdf\"#\"temp.pdf\"#\n",
    "ax = history_df.plot()\n",
    "\n",
    "ratio = 0.95\n",
    "xleft, xright = ax.get_xlim()\n",
    "ybottom, ytop = ax.get_ylim()\n",
    "# the abs method is used to make sure that all numbers are positive\n",
    "# because x and y axis of an axes maybe inversed.\n",
    "ax.set_aspect(abs((xright-xleft)/(ybottom-ytop))*ratio)\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('objective function (include both reconstruct_loss, kl_loss)')\n",
    "ax.set_title('')\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50176)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2000)         100354000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2000)         8000        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2000)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          1000500     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          1000500     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 500)          2000        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 500)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 500)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 500)          0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 102,367,000\n",
      "Trainable params: 102,361,000\n",
      "Non-trainable params: 6,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#extract the encoder part\n",
    "\n",
    "# Model to compress input\n",
    "#encoder = Model(rnaseq_input, [z_mean_encoded, z_log_var_encoded])\n",
    "encoder = Model(rnaseq_input, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50176)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2000)         100354000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2000)         8000        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2000)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          1000500     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          1000500     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 500)          2000        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 500)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 500)          0           batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 102,367,000\n",
      "Trainable params: 102,361,000\n",
      "Non-trainable params: 6,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder2 = Model(rnaseq_input, [z_mean_encoded, z_log_var_encoded])\n",
    "encoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "z_df = encoder.predict_on_batch(Exprframe_test)\n",
    "\n",
    "z_df = pd.DataFrame(z_df, index=Exprframe_test.index)\n",
    "\n",
    "z_df.columns.name = 'sample_id'\n",
    "z_df.columns = z_df.columns + 1\n",
    "z_df.head(10)\n",
    "\n",
    "[z_mean_d, z_log_var_d]= encoder2.predict_on_batch(Exprframe_test)\n",
    "z_mean_df = pd.DataFrame(z_mean_d, index=Exprframe_test.index)\n",
    "\n",
    "z_mean_df.columns.name = 'sample_id'\n",
    "z_mean_df.columns = z_mean_df.columns + 1\n",
    "\n",
    "\n",
    "z_log_var_df = pd.DataFrame(z_log_var_d, index=Exprframe_test.index)\n",
    "\n",
    "z_log_var_df.columns.name = 'sample_id'\n",
    "z_log_var_df.columns = z_log_var_df.columns + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50176)             100402176 \n",
      "=================================================================\n",
      "Total params: 101,404,176\n",
      "Trainable params: 101,404,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim, ))  # can generate from any sampled z vector\n",
    "\n",
    "_x_decoded_l1 = decoderl1_reconstruct(decoder_input)\n",
    "_x_decoded_l0 = decoderl0_reconstruct(_x_decoded_l1)\n",
    "\n",
    "decoder = Model(decoder_input, _x_decoded_l0)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe reconstruction fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rotate90-04-CON-D09-R.png</th>\n",
       "      <td>0.684174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927903</td>\n",
       "      <td>0.305281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611977</td>\n",
       "      <td>0.124129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629954</td>\n",
       "      <td>0.315790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotate180-09-CON-D25-R.png</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotate270-06-CON-D25-L.png</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043805</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>0.047249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0    1    2    3         4         5  \\\n",
       "rotate90-04-CON-D09-R.png   0.684174  0.0  0.0  0.0  0.927903  0.305281   \n",
       "rotate180-09-CON-D25-R.png  0.000000  0.0  0.0  0.0  0.045503  0.000000   \n",
       "rotate270-06-CON-D25-L.png  0.000000  0.0  0.0  0.0  0.043805  0.091448   \n",
       "\n",
       "                                   6    7         8         9    ...     \\\n",
       "rotate90-04-CON-D09-R.png   1.000000  0.0  0.060666  0.789363    ...      \n",
       "rotate180-09-CON-D25-R.png  0.050935  0.0  0.034668  0.000000    ...      \n",
       "rotate270-06-CON-D25-L.png  0.047249  0.0  0.000000  0.168737    ...      \n",
       "\n",
       "                            50166  50167  50168  50169     50170     50171  \\\n",
       "rotate90-04-CON-D09-R.png     0.0    0.0    0.0    0.0  0.611977  0.124129   \n",
       "rotate180-09-CON-D25-R.png    0.0    0.0    0.0    0.0  0.000000  0.019583   \n",
       "rotate270-06-CON-D25-L.png    0.0    0.0    0.0    0.0  0.000000  0.021884   \n",
       "\n",
       "                            50172  50173     50174     50175  \n",
       "rotate90-04-CON-D09-R.png     0.0    0.0  0.629954  0.315790  \n",
       "rotate180-09-CON-D25-R.png    0.0    0.0  0.000000  0.015100  \n",
       "rotate270-06-CON-D25-L.png    0.0    0.0  0.000000  0.036162  \n",
       "\n",
       "[3 rows x 50176 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original input RNAseq data\n",
    "rnaseq_df = Exprframe_test\n",
    "rnaseq_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rotate90-04-CON-D09-R.png</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695071</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.699118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601766</td>\n",
       "      <td>0.115412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522355</td>\n",
       "      <td>0.259229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotate180-09-CON-D25-R.png</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotate270-06-CON-D25-L.png</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049558</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>0.076892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0    1    2    3         4         5         6  \\\n",
       "rotate90-04-CON-D09-R.png   0.0  0.0  0.0  0.0  0.695071  0.024727  0.699118   \n",
       "rotate180-09-CON-D25-R.png  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "rotate270-06-CON-D25-L.png  0.0  0.0  0.0  0.0  0.049558  0.086069  0.076892   \n",
       "\n",
       "                              7    8         9    ...     50166  50167  50168  \\\n",
       "rotate90-04-CON-D09-R.png   0.0  0.0  0.148686    ...       0.0    0.0    0.0   \n",
       "rotate180-09-CON-D25-R.png  0.0  0.0  0.000000    ...       0.0    0.0    0.0   \n",
       "rotate270-06-CON-D25-L.png  0.0  0.0  0.099687    ...       0.0    0.0    0.0   \n",
       "\n",
       "                            50169     50170     50171  50172  50173     50174  \\\n",
       "rotate90-04-CON-D09-R.png     0.0  0.601766  0.115412    0.0    0.0  0.522355   \n",
       "rotate180-09-CON-D25-R.png    0.0  0.000000  0.009035    0.0    0.0  0.000000   \n",
       "rotate270-06-CON-D25-L.png    0.0  0.000000  0.036089    0.0    0.0  0.000000   \n",
       "\n",
       "                               50175  \n",
       "rotate90-04-CON-D09-R.png   0.259229  \n",
       "rotate180-09-CON-D25-R.png  0.038250  \n",
       "rotate270-06-CON-D25-L.png  0.041678  \n",
       "\n",
       "[3 rows x 50176 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well does the model reconstruct the input RNAseq data\n",
    "input_rnaseq_reconstruct = decoder.predict(np.array(z_df))\n",
    "input_rnaseq_reconstruct = pd.DataFrame(input_rnaseq_reconstruct, index=rnaseq_df.index,\n",
    "                                        columns=rnaseq_df.columns)\n",
    "input_rnaseq_reconstruct.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the fidelity\n",
    "reconstruction_fidelity = abs(rnaseq_df - input_rnaseq_reconstruct)\n",
    "\n",
    "reconstruction_loss = reconstruction_fidelity.mean(axis = 1)\n",
    "\n",
    "#print(reconstruction_loss)\n",
    "\n",
    "gene_mean = reconstruction_fidelity.mean(axis=0)\n",
    "gene_abssum = reconstruction_fidelity.abs().sum(axis=0).divide(rnaseq_df.shape[0])\n",
    "gene_summary = pd.DataFrame([gene_mean, gene_abssum], index=['gene mean', 'gene abs(sum)']).T\n",
    "#gene_summary.sort_values(by='gene abs(sum)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out the mean reconstruction loss and the mean KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean reconstruction loss for each data point is: 0.02884974861\n"
     ]
    }
   ],
   "source": [
    "# L1 loss: losses.mean_absolute_error\n",
    "reconstruction_loss_used = losses.mean_absolute_error(rnaseq_df, input_rnaseq_reconstruct) #* original_dim\n",
    "with tf.Session() as sess:\n",
    "    #print the reconstruction loss that we calculated\n",
    "    mean_reconstruct_loss = sess.run(K.mean(reconstruction_loss_used))\n",
    "    print (\"The mean reconstruction loss for each data point is: %.11f\" % mean_reconstruct_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean KL loss for each data point is: 0.21881414950\n"
     ]
    }
   ],
   "source": [
    "kl_loss = - 0.5 * K.sum(1 + z_log_var_d - K.square(z_mean_d) - \n",
    "                                K.exp(z_log_var_d), axis=-1) / latent_dim\n",
    "with tf.Session() as sess:\n",
    "    #print the kl loss that we calculated\n",
    "    mean_kl_loss = sess.run(K.mean(kl_loss))\n",
    "    print (\"The mean KL loss for each data point is: %.11f\" %mean_kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined mean loss for each data point is: 0.24766389811\n",
      "The current alpha choice for reconstruction loss + alpha*kl loss is:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"The combined mean loss for each data point is: %.11f\" % (mean_reconstruct_loss + alpha * mean_kl_loss))\n",
    "print (\"The current alpha choice for reconstruction loss + alpha*kl loss is: \", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "#encoded_rnaseq_df\n",
    "\n",
    "z_df = encoder.predict_on_batch(Exprframe)\n",
    "\n",
    "z_df = pd.DataFrame(z_df, index=Exprframe.index)\n",
    "\n",
    "z_df.columns.name = 'sample_id'\n",
    "z_df.columns = z_df.columns + 1\n",
    "z_df.head(10)\n",
    "\n",
    "encoded_file = path + pred_save_path + \"VAE_compressed_features_rotations.csv\"\n",
    "#encoded_file = \"counts_data/vae_compressed/encoded_4_cancers_rnaseq_vae(perSp,a0,unlabel,0.2_var,3LF6k,z500,minmax).tsv\"\n",
    "z_df.to_csv(encoded_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
