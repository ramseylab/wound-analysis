{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "from models.unets import Unet2D\n",
    "#from models.separable_unet import Separable_Unet2D\n",
    "from models.deeplab import Deeplabv3, relu6, BilinearUpsampling, DepthwiseConv2D\n",
    "from models.FCN import FCN_Vgg16_16s\n",
    "from models.SegNet import SegNet\n",
    "\n",
    "from utils.learning.metrics import dice_coef, precision, recall\n",
    "from utils.BilinearUpSampling import BilinearUpSampling2D\n",
    "from utils.io.data import load_data, save_results, save_rgb_results, save_history, load_test_images, DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "input_dim_x = 224\n",
    "input_dim_y = 224\n",
    "color_space = 'rgb'\n",
    "path = './data/all_dog_wounds_noAugmentation/'#all_dog_wounds_noAugmentation#Medetec_foot_ulcer_224#Dog_wound_low_resolution#dog9_10_test\n",
    "weight_file_name = 'Unet-dog-w-augment-2021-07-20.hdf5'\n",
    "pred_save_path = 'Unet-dog-w-augment-2021-07-20/'\n",
    "\n",
    "#data_gen = DataGen(path, split_ratio=0.0, x=input_dim_x, y=input_dim_y, color_space=color_space)\n",
    "x_test, test_label_filenames_list = load_test_images(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "input_dim_x = 224\n",
    "input_dim_y = 224\n",
    "color_space = 'rgb'\n",
    "path = './data/all_dog_wounds_noAugmentation/'#all_dog_wounds_noAugmentation#Medetec_foot_ulcer_224#Dog_wound_low_resolution#dog9_10_test\n",
    "weight_file_name = 'new.hdf5'\n",
    "pred_save_path = 'Unet-dog-w-augment-2021-07-20/'\n",
    "\n",
    "#data_gen = DataGen(path, split_ratio=0.0, x=input_dim_x, y=input_dim_y, color_space=color_space)\n",
    "x_test, test_label_filenames_list = load_test_images(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### get unet model\n",
    "#unet2d = Unet2D(n_filters=64, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "#model = unet2d.get_unet_model_yuanqing()\n",
    "model = load_model('./trained_models/' + weight_file_name,\n",
    "                   custom_objects={'dice_coef': dice_coef,\n",
    "                                  'precision':precision,\n",
    "                                  'recall':recall})\n",
    "\n",
    "# ### get separable unet model\n",
    "# sep_unet = Separable_Unet2D(n_filters=64, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "# model, model_name = sep_unet.get_sep_unet_v2()\n",
    "# model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#                , custom_objects={'dice_coef': dice_coef,\n",
    "#                                  'relu6':relu6,\n",
    "#                                  'DepthwiseConv2D':DepthwiseConv2D,\n",
    "#                                  'BilinearUpsampling':BilinearUpsampling})\n",
    "\n",
    "# ### get VGG16 model\n",
    "# model, model_name = FCN_Vgg16_16s(input_shape=(input_dim_x, input_dim_y, 3))\n",
    "# with CustomObjectScope({'BilinearUpSampling2D':BilinearUpSampling2D}):\n",
    "#     model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#                    , custom_objects={'dice_coef': dice_coef})\n",
    "\n",
    "# ### get mobilenetv2 model\n",
    "#model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
    "#model = load_model('./azh_wound_care_center_diabetic_foot_training_history/' + weight_file_name\n",
    "#               , custom_objects={'dice_coef': dice_coef,\n",
    "#                                 'relu6':relu6,\n",
    "#                                 'DepthwiseConv2D':DepthwiseConv2D,\n",
    "#                                 'BilinearUpsampling':BilinearUpsampling})\n",
    "\n",
    "# ### get segnet model\n",
    "######### SegNet ##########\n",
    "#segnet = SegNet(n_filters=32, input_dim_x=input_dim_x, input_dim_y=input_dim_y, num_channels=3)\n",
    "#model, model_name = segnet.get_SegNet()\n",
    "#model = load_model('./merged_azh_dog1_8_history/' + weight_file_name,\n",
    "#                   custom_objects={'dice_coef': dice_coef,\n",
    "#                                  'precision':precision,\n",
    "#                                  'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 3 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 2 590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 590080      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 590080      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 590080      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 2 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 1 295040      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 131200      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 2 0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 1 295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 1 147584      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 73792       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 32832       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 1 0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 6 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 3 18464       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 3 8224        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 6 0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 3 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 3 9248        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 3 0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 1 4624        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 2064        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           conv2d_26[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 2320        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 3 435         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 1 4           conv2d_29[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,834,839\n",
      "Trainable params: 4,834,839\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predicted mask images\n",
    "prediction = model.predict(x_test, verbose=1)\n",
    "save_results(prediction, 'rgb', path + 'predictions/' + pred_save_path, test_label_filenames_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the wound area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame to store wound area results\n",
    "wound_area_df = pd.DataFrame(columns = ['Pixel_Area'], index = test_label_filenames_list) \n",
    "\n",
    "for i in range(len(test_label_filenames_list)):\n",
    "    pred = prediction[i]\n",
    "    ret, pred_bw = cv2.threshold(pred*255., 127, 255, cv2.THRESH_BINARY) \n",
    "    wound_area_df.iloc[i,0] = cv2.countNonZero(pred_bw)\n",
    "#print(wound_area_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract date and dog label information from row name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['-01-CON-D00-L.png', '-01-CON-D02-L.png', '-01-CON-D04-L.png',\n",
      "       '-01-CON-D07-L.png', '-01-CON-D09-L.png', '-01-CON-D11-L.png',\n",
      "       '-01-CON-D14-L.png', '-01-CON-D16-L.png', '-01-CON-D18-L.png',\n",
      "       '-01-CON-D21-L.png',\n",
      "       ...\n",
      "       'rotate90-10-CON-D04-R.png', 'rotate90-10-CON-D07-R.png',\n",
      "       'rotate90-10-CON-D09-R.png', 'rotate90-10-CON-D11-R.png',\n",
      "       'rotate90-10-CON-D14-R.png', 'rotate90-10-CON-D16-R.png',\n",
      "       'rotate90-10-CON-D18-R.png', 'rotate90-10-CON-D21-R.png',\n",
      "       'rotate90-10-CON-D23-R.png', 'rotate90-10-CON-D25-R.png'],\n",
      "      dtype='object', length=544)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for i in range(len(wound_area_df.index)):\n",
    "    wound_area_df.loc[wound_area_df.index[i], 'Day'] = int(wound_area_df.index[i].split('-D')[1].split('-')[0])\n",
    "    wound_area_df.loc[wound_area_df.index[i], 'Dog_label'] = wound_area_df.index[i].split('-')[1].split('-CON')[0]\n",
    "print(wound_area_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the ratio by calculate the pixel length of 1cm ruler on image\n",
    "\n",
    "Currently just manually count pixel length of 1 cm ruler\n",
    "Alternatives: \n",
    "1. Hough transform for line detection\n",
    "2. A separate NN for ruler detection, and count the 1 cm ruler area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dog 9 and 10 ration manually picked\n",
    "#wound_area_df.loc[:,'Ratio'] = [56, 59, 52, 50, 60, 61, 59, 63, 61, 64, 71, 73, 74, 114,\n",
    "#                             50, 54, 54, 57, 57, 59, 50, 68, 81, 70, 68, 59]\n",
    "\n",
    "# All dog wound images' ratio, could also read in from file wound_image_labels.csv\n",
    "wound_area_df.loc[:,'Ratio'] = [35,66,53,54,77,70,62,72,71,71,89,81,65,68,69,30,48,60,66,65,\n",
    "66,66,64,74,57,69,75,73,74,82,35,56,51,62,69,74,79,90,73,66,73,72,69,74,52,33,40,52,58,66,69,\n",
    "48,69,68,55,62,64,79,83,64,50,58,64,75,75,96,70,75,63,72,51,48,53,45,53,53,54,50,55,54,67,72,\n",
    "78,69,60,51,50,57,53,60,53,55,70,71,80,91,86,70,55,57,52,65,60,69,62,75,80,76,80,82,56,59,52,\n",
    "50,60,61,59,63,61,64,71,73,74,114,50,54,54,57,57,59,50,68,81,70,68,59]*4\n",
    "\n",
    "wound_area_df.loc[:,'Area_mm2'] = wound_area_df.loc[:,'Pixel_Area']*100 / (wound_area_df.loc[:,'Ratio']**2)\n",
    "#print(wound_area_df)\n",
    "wound_area_df = wound_area_df[['Day', 'Dog_label', 'Area_mm2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Day Dog_label Area_mm2\n",
      "-07-CON-D00-R.png            0.0        07    451.2\n",
      "-07-CON-D02-R.png            2.0        07  526.008\n",
      "-07-CON-D04-R.png            4.0        07  428.765\n",
      "-07-CON-D07-R.png            7.0        07  450.778\n",
      "-07-CON-D09-R.png            9.0        07  244.357\n",
      "-07-CON-D11-R.png           11.0        07  146.116\n",
      "-07-CON-D14-R.png           14.0        07  81.4694\n",
      "-07-CON-D16-R.png           16.0        07  64.4118\n",
      "-07-CON-D18-R.png           18.0        07  38.3125\n",
      "-07-CON-D21-R.png           21.0        07  28.7284\n",
      "-07-CON-D23-R.png           23.0        07  17.2255\n",
      "-07-CON-D25-R.png           25.0        07  5.91837\n",
      "rotate180-07-CON-D00-R.png   0.0        07   449.44\n",
      "rotate180-07-CON-D02-R.png   2.0        07  537.765\n",
      "rotate180-07-CON-D04-R.png   4.0        07  426.522\n",
      "rotate180-07-CON-D07-R.png   7.0        07  449.056\n",
      "rotate180-07-CON-D09-R.png   9.0        07  243.005\n",
      "rotate180-07-CON-D11-R.png  11.0        07  136.959\n",
      "rotate180-07-CON-D14-R.png  14.0        07  82.7755\n",
      "rotate180-07-CON-D16-R.png  16.0        07  65.4434\n",
      "rotate180-07-CON-D18-R.png  18.0        07  32.9375\n",
      "rotate180-07-CON-D21-R.png  21.0        07  29.8273\n",
      "rotate180-07-CON-D23-R.png  23.0        07  11.6955\n",
      "rotate180-07-CON-D25-R.png  25.0        07  8.91837\n",
      "rotate270-07-CON-D00-R.png   0.0        07   438.48\n",
      "rotate270-07-CON-D02-R.png   2.0        07  533.241\n",
      "rotate270-07-CON-D04-R.png   4.0        07  421.289\n",
      "rotate270-07-CON-D07-R.png   7.0        07  448.917\n",
      "rotate270-07-CON-D09-R.png   9.0        07  251.406\n",
      "rotate270-07-CON-D11-R.png  11.0        07  144.165\n",
      "rotate270-07-CON-D14-R.png  14.0        07  88.8571\n",
      "rotate270-07-CON-D16-R.png  16.0        07  64.1738\n",
      "rotate270-07-CON-D18-R.png  18.0        07  32.3906\n",
      "rotate270-07-CON-D21-R.png  21.0        07  26.6755\n",
      "rotate270-07-CON-D23-R.png  23.0        07  14.6701\n",
      "rotate270-07-CON-D25-R.png  25.0        07  8.30612\n",
      "rotate90-07-CON-D00-R.png    0.0        07   449.72\n",
      "rotate90-07-CON-D02-R.png    2.0        07  534.472\n",
      "rotate90-07-CON-D04-R.png    4.0        07  426.949\n",
      "rotate90-07-CON-D07-R.png    7.0        07  446.722\n",
      "rotate90-07-CON-D09-R.png    9.0        07  246.137\n",
      "rotate90-07-CON-D11-R.png   11.0        07  138.149\n",
      "rotate90-07-CON-D14-R.png   14.0        07  89.8776\n",
      "rotate90-07-CON-D16-R.png   16.0        07  66.8121\n",
      "rotate90-07-CON-D18-R.png   18.0        07  35.7969\n",
      "rotate90-07-CON-D21-R.png   21.0        07  26.5668\n",
      "rotate90-07-CON-D23-R.png   23.0        07  9.77555\n",
      "rotate90-07-CON-D25-R.png   25.0        07  7.30612\n"
     ]
    }
   ],
   "source": [
    "print(wound_area_df[wound_area_df.Dog_label == \"07\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the intermediate layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(544, 14, 14, 256)\n",
      "(544, 50176)\n",
      "Are there any NA value? :  False\n"
     ]
    }
   ],
   "source": [
    "# Extract the intermediate layer as features\n",
    "########### SegNet ####################################\n",
    "# !check the summary to confirm which layer to extract\n",
    "#\n",
    "# Segnet: use 'conv2d_5'\n",
    "# Unet: use 'conv2d_12'\n",
    "\n",
    "layer_name = 'conv2d_12'\n",
    "#layer_name = 'conv2d_5'\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_test)\n",
    "print(intermediate_output.shape)\n",
    "# flatten the extracted features using the 1-3 column\n",
    "intermediate_output_flatten = intermediate_output.reshape((intermediate_output.shape[0],\n",
    "                                                           intermediate_output.shape[1] * \n",
    "                                                           intermediate_output.shape[2] * \n",
    "                                                           intermediate_output.shape[3]))\n",
    "print(intermediate_output_flatten.shape)\n",
    "print(\"Are there any NA value? : \", np.any(np.isnan(intermediate_output_flatten)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3         4      5      6      7      8      9      \\\n",
       "0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0  0.954642    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...     50166  50167  50168  50169  50170  50171  50172  50173  50174  \\\n",
       "0  ...  0.141906    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  ...  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  ...  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      50175  \n",
       "0  0.000000  \n",
       "1  0.005005  \n",
       "2  0.000000  \n",
       "\n",
       "[3 rows x 50176 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use PCA to reduce dimension to 50 for the regression model\n",
    "\n",
    "# change to a pandas dataframe\n",
    "og_data = pd.DataFrame(intermediate_output_flatten, index = test_label_filenames_list)\n",
    "#og_data.shape\n",
    "#print(og_data)\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "#minmax data transformation\n",
    "from sklearn import preprocessing\n",
    "#built up data frame\n",
    "from pandas import DataFrame, Series\n",
    "norm_data = og_data\n",
    "\n",
    "# Scale RNAseq data using zero-one normalization\n",
    "norm_data_zerone = preprocessing.MinMaxScaler().fit_transform(norm_data)\n",
    "\n",
    "# If select the minmax method\n",
    "norm_data = pd.DataFrame(norm_data_zerone)\n",
    "norm_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Projection using Minka's MLE\n",
    "from sklearn.decomposition import PCA\n",
    "# use this, if selecting the amount of variance that needs to be explained is greater than the percentage specified by n_components.\n",
    "# or assign a certain components number, e.g. 50\n",
    "pca = PCA(n_components = 0.95, svd_solver = 'full')\n",
    "#pca = PCA(n_components = 50, svd_solver = 'auto')\n",
    "#print(pca)\n",
    "principalComponents = pca.fit_transform(norm_data)\n",
    "principalDf = pd.DataFrame(data = principalComponents, index = test_label_filenames_list)\n",
    "#principalDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Dataset Explained Variance')\n",
    "#plt.savefig('PCA_Explained_Variance(thre_0.9).png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE compression\n",
    "## Split 10% of the data as test set randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of training dataset is:  (490, 50176)\n"
     ]
    }
   ],
   "source": [
    "#import the data as training data\n",
    "#set the random state to 42\n",
    "\n",
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "Exprframe_test = norm_data.sample(frac=test_set_percent, random_state = 42)\n",
    "Exprframe_train = norm_data.drop(Exprframe_test.index)\n",
    "print(\"The dimension of training dataset is: \",Exprframe_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions and classes\n",
    "* This will facilitate connections between layers and also custom hyperparameters\n",
    "\n",
    "## Implementing Warm-up as described in Sonderby et al. LVAE\n",
    "\n",
    "* This is modified code from https://github.com/fchollet/keras/issues/2595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras import losses\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "from keras import utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "    This function is borrowed from:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    #def vae_loss(self, x_input, x_decoded):\n",
    "    #    reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "    #    kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "    #                            K.exp(z_log_var_encoded), axis=-1)\n",
    "    #    return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "    \n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        #per sample\n",
    "        reconstruction_loss = original_dim * losses.mean_absolute_error(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        \n",
    "        #\n",
    "        #per data point\n",
    "        #reconstruction_loss = losses.mean_absolute_error(x_input, x_decoded)\n",
    "        #kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "        #                        K.exp(z_log_var_encoded), axis=-1) / latent_dim\n",
    "        \n",
    "        \n",
    "        return K.mean(reconstruction_loss + alpha * (kl_loss))#K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x\n",
    "    \n",
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input layer is:  50176\n",
      "The batch size is:  4\n"
     ]
    }
   ],
   "source": [
    "# Set hyper parameters\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "original_dim = Exprframe_train.shape[1]\n",
    "print(\"The dimension of input layer is: \", original_dim)\n",
    "\n",
    "layer1_dim, layer2_dim, layer3_dim, layer4_dim, layer5_dim, latent_dim = 6000, 3000, 1000,500,100,50\n",
    "\n",
    "batch_size = 4 #Exprframe_train.shape[0]\n",
    "print(\"The batch size is: \", batch_size)\n",
    "epochs, learning_rate = 1200, 0.002\n",
    "\n",
    "#set kernel initializer\n",
    "# Casey paper 'glorot_uniform'\n",
    "#initial_method = 'glorot_uniform'\n",
    "#initial_method = keras.initializers.glorot_uniform(seed=807)\n",
    "initial_method = keras.initializers.glorot_normal(seed=42)\n",
    "\n",
    "epsilon_std, alpha, beta, kappa = 1.0, 1.0, K.variable(0), 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple neural network version with two layers\n",
    "#Layer 1\n",
    "# Input place holder for RNAseq data with specific input size\n",
    "rnaseq_input = Input(shape=(original_dim, ))\n",
    "\n",
    "#L1\n",
    "l1_dense_linear = Dense(layer1_dim, kernel_initializer=initial_method)(rnaseq_input)\n",
    "l1_dense_batchnorm = BatchNormalization()(l1_dense_linear)\n",
    "l1 = Activation('relu')(l1_dense_batchnorm)\n",
    "\n",
    "#l2\n",
    "l2_dense_linear = Dense(layer2_dim, kernel_initializer=initial_method)(l1)\n",
    "l2_dense_batchnorm = BatchNormalization()(l2_dense_linear)\n",
    "l2 = Activation('relu')(l2_dense_batchnorm)\n",
    "\n",
    "#l3\n",
    "l3_dense_linear = Dense(layer3_dim, kernel_initializer=initial_method)(l2)\n",
    "l3_dense_batchnorm = BatchNormalization()(l3_dense_linear)\n",
    "l3 = Activation('relu')(l3_dense_batchnorm)\n",
    "\n",
    "#l4\n",
    "l4_dense_linear = Dense(layer4_dim, kernel_initializer=initial_method)(l3)\n",
    "l4_dense_batchnorm = BatchNormalization()(l4_dense_linear)\n",
    "l4 = Activation('relu')(l4_dense_batchnorm)\n",
    "\n",
    "#l5\n",
    "l5_dense_linear = Dense(layer5_dim, kernel_initializer=initial_method)(l4)\n",
    "l5_dense_batchnorm = BatchNormalization()(l5_dense_linear)\n",
    "l5 = Activation('relu')(l5_dense_batchnorm)\n",
    "\n",
    "#Layer 6\n",
    "# Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "# Each layer is initialized with glorot uniform weights and each step (dense connections,\n",
    "# batch norm, and relu activation) are funneled separately\n",
    "# Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l5)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer=initial_method)(l5)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# return the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoding layers have 6 layers and relu activation\n",
    "decoderl5_reconstruct = Dense(layer5_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l5 = decoderl5_reconstruct(z)\n",
    "\n",
    "decoderl4_reconstruct = Dense(layer4_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l4 = decoderl4_reconstruct(decoder_l5)\n",
    "\n",
    "decoderl3_reconstruct = Dense(layer3_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l3 = decoderl3_reconstruct(decoder_l4)\n",
    "\n",
    "decoderl2_reconstruct = Dense(layer2_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l2 = decoderl2_reconstruct(decoder_l3)\n",
    "\n",
    "decoderl1_reconstruct = Dense(layer1_dim, kernel_initializer=initial_method, activation='relu')\n",
    "decoder_l1 = decoderl1_reconstruct(decoder_l2)\n",
    "\n",
    "decoderl0_reconstruct = Dense(original_dim, kernel_initializer=initial_method, activation='relu')\n",
    "rnaseq_reconstruct = decoderl0_reconstruct(decoder_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the encoder and decoder to make the VAE\n",
    "\n",
    "* The CustomVariationalLayer() includes the VAE loss function (reconstruction + (beta * KL)), which is what will drive our model to learn an interpretable representation of gene expression space.\n",
    "\n",
    "* The VAE is compiled with an Adam optimizer and built-in custom loss function. The loss_weights parameter ensures beta is updated at each epoch end callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50176)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6000)         301062000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 6000)         24000       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 6000)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3000)         18003000    activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3000)         12000       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3000)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         3001000     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000)         4000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1000)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          500500      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 500)          2000        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 500)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          50100       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100)          400         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 50)           5050        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50)           200         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50)           200         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 50)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 50)           0           activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          5100        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 500)          50500       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1000)         501000      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3000)         3003000     dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 6000)         18006000    dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 50176)        301106176   dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer (Custo (None, 50176)        0           input_1[0][0]                    \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 645,341,276\n",
      "Trainable params: 645,319,876\n",
      "Non-trainable params: 21,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "vae_layer = CustomVariationalLayer()([rnaseq_input, rnaseq_reconstruct])\n",
    "vae = Model(rnaseq_input, vae_layer)\n",
    "vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n",
    "\n",
    "#########################################################################\n",
    "#only use to manually set initial weights, otherwise change the initializer\n",
    "weights = vae.get_weights()\n",
    "#new_weight = [item*0+0.01 for item in weights]\n",
    "#vae.set_weights(new_weight)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "* The training data is shuffled after every epoch and 10% of the data is heldout for calculating validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hist = vae.fit(np.array(Exprframe_train),\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               verbose=0,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(np.array(Exprframe_test), None),\n",
    "               callbacks=[WarmUpCallback(beta, kappa)])#,\n",
    "                          #TQDMNotebookCallback(leave_inner=True, leave_outer=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize VAE training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "history_df = history_df.iloc[60:1199]\n",
    "\n",
    "hist_plot_file = \"temp.pdf\"#\n",
    "ax = history_df.plot()\n",
    "\n",
    "ratio = 0.95\n",
    "xleft, xright = ax.get_xlim()\n",
    "ybottom, ytop = ax.get_ylim()\n",
    "# the abs method is used to make sure that all numbers are positive\n",
    "# because x and y axis of an axes maybe inversed.\n",
    "ax.set_aspect(abs((xright-xleft)/(ybottom-ytop))*ratio)\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('objective function (include both reconstruct_loss, kl_loss)')\n",
    "ax.set_title('')\n",
    "fig = ax.get_figure()\n",
    "#fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the encoder part\n",
    "encoder = Model(rnaseq_input, z)\n",
    "#encoder.summary()\n",
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "z_df = encoder.predict_on_batch(Exprframe_test)\n",
    "\n",
    "z_df = pd.DataFrame(z_df, index=Exprframe_test.index)\n",
    "\n",
    "z_df.columns.name = 'sample_id'\n",
    "z_df.columns = z_df.columns + 1\n",
    "z_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim, ))  # can generate from any sampled z vector\n",
    "\n",
    "_x_decoded_l5 = decoderl5_reconstruct(decoder_input)\n",
    "_x_decoded_l4 = decoderl4_reconstruct(_x_decoded_l5)\n",
    "_x_decoded_l3 = decoderl3_reconstruct(_x_decoded_l4)\n",
    "\n",
    "_x_decoded_l2 = decoderl2_reconstruct(_x_decoded_l3)\n",
    "\n",
    "_x_decoded_l1 = decoderl1_reconstruct(_x_decoded_l2)\n",
    "_x_decoded_l0 = decoderl0_reconstruct(_x_decoded_l1)\n",
    "\n",
    "decoder = Model(decoder_input, _x_decoded_l0)\n",
    "#decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe reconstruction fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original input RNAseq data\n",
    "Exprframe_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does the model reconstruct the input RNAseq data\n",
    "input_rnaseq_reconstruct = decoder.predict(np.array(z_df))\n",
    "input_rnaseq_reconstruct = pd.DataFrame(input_rnaseq_reconstruct, index=Exprframe_test.index,\n",
    "                                        columns=Exprframe_test.columns)\n",
    "input_rnaseq_reconstruct.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the mean reconstruction loss and the mean KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# L1 loss: losses.mean_absolute_error\n",
    "reconstruction_loss_used = losses.mean_absolute_error(Exprframe_test, input_rnaseq_reconstruct) #* original_dim\n",
    "with tf.Session() as sess:\n",
    "    #print the reconstruction loss that we calculated\n",
    "    mean_reconstruct_loss = sess.run(K.mean(reconstruction_loss_used))\n",
    "    print (\"The mean reconstruction loss for each data point is: %.11f\" % mean_reconstruct_loss)\n",
    "\n",
    "#kl_loss = - 0.5 * K.sum(1 + z_log_var_d - K.square(z_mean_d) - \n",
    "#                                K.exp(z_log_var_d), axis=-1) / latent_dim\n",
    "#with tf.Session() as sess:\n",
    "    #print the kl loss that we calculated\n",
    "#    mean_kl_loss = sess.run(K.mean(kl_loss))\n",
    "#    print (\"The mean KL loss for each data point is: %.11f\" %mean_kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with area/day information and Save the compressed encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For uncompressed data\n",
    "#out_df = og_data.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# For PCA compressed:\n",
    "out_df = principalDf.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# For VAE compressed:\n",
    "#z_df = encoder.predict_on_batch(Exprframe)\n",
    "#z_df = pd.DataFrame(z_df, index=Exprframe.index)\n",
    "#z_df.columns.name = 'sample_id'\n",
    "#z_df.columns = z_df.columns + 1\n",
    "#out_df = z_df.merge(wound_area_df, how='outer', left_index=True, right_index=True)\n",
    "#out_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_file_path = path + 'extracted_features/' + pred_save_path\n",
    "# uncompressed: uncompressed_features_rotations.csv\n",
    "# pca compressed: pca_compressed_features_rotations.csv\n",
    "# vae compressed: VAE-1_compressed_features_rotations.csv\n",
    "out_df.to_csv(encoded_file_path + 'pca_compressed_features_rotations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(path + 'predictions/' + pred_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_batch, label_batch in data_gen.generate_data(batch_size=len(x_test), test=True):\n",
    "#    prediction = model.predict(image_batch, verbose=1)\n",
    "    #save_results(prediction, 'rgb', path + 'test/predictions/' + pred_save_path, test_label_filenames_list)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
